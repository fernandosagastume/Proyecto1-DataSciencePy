{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto #1 - Ciencia de Datos en Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan las librerias que se utilizan en el proyecto\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación de Datos en 2 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 6)\n",
      "[[2.08500e+05 7.00000e+00 8.56000e+02 8.00000e+00 2.00300e+03 6.50000e+01]\n",
      " [1.81500e+05 6.00000e+00 1.26200e+03 6.00000e+00 1.97600e+03 8.00000e+01]\n",
      " [2.23500e+05 7.00000e+00 9.20000e+02 6.00000e+00 2.00100e+03 6.80000e+01]\n",
      " ...\n",
      " [2.66500e+05 7.00000e+00 1.18800e+03 9.00000e+00 1.94100e+03 6.60000e+01]\n",
      " [1.42125e+05 5.00000e+00 1.07800e+03 5.00000e+00 1.95000e+03 6.80000e+01]\n",
      " [1.47500e+05 5.00000e+00 1.25600e+03 6.00000e+00 1.96500e+03 7.50000e+01]]\n"
     ]
    }
   ],
   "source": [
    "# Se cargan los datos para ser separados posteriormente\n",
    "df = np.load(\"data/proyecto_training_data.npy\")\n",
    "print(df.shape)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se calcula el indice en el que se va partir la data para la validación y pruebas\n",
    "idx_split = int(df.shape[0] * 0.8)\n",
    "\n",
    "# Dataset de validacion y pruebas\n",
    "val_set = df[idx_split:, :] # Se toman los valores a partir del índice (sin incluirlo) - 20% de los datos - validación y pruebas\n",
    "entrenamiento_dataset = df[:idx_split, :] # Se toman los valores del índice para atrás - 80% de los datos - entrenamiento\n",
    "\n",
    "# Se separa val_set de tal manera que podamos tener datasets tanto para validación como para pruebas\n",
    "val_idx_split = int(val_set.shape[0] * 0.5) # 0.5 para obtener la mitad de los datos para validación y la otra mitad para pruebas\n",
    "\n",
    "val_dataset = val_set[:val_idx_split, :] # Dataset de validación\n",
    "pruebas_dataset = val_set[val_idx_split:, :] # Dataset de pruebas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media del dataset es:\n",
      "[1.80921196e+05 6.09931507e+00 1.16262671e+03 6.51780822e+00\n",
      " 1.97126781e+03 7.00499584e+01]\n",
      "\n",
      "El valor máximo de cada variable del dataset es:\n",
      "[7.550e+05 1.000e+01 4.692e+03 1.400e+01 2.010e+03 3.130e+02]\n",
      "\n",
      "El valor mínimo de cada variable del dataset es:\n",
      "[3.490e+04 1.000e+00 3.340e+02 2.000e+00 1.872e+03 2.100e+01]\n",
      "\n",
      "El rango de cada variable del dataset es:\n",
      "[7.201e+05 9.000e+00 4.358e+03 1.200e+01 1.380e+02 2.920e+02]\n",
      "\n",
      "La desviación estándar de cada variable del dataset es:\n",
      "[7.94152919e+04 1.38252284e+00 3.86455322e+02 1.62483655e+00\n",
      " 3.01925588e+01 2.42746394e+01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculando la media del dataset\n",
    "media = np.nanmean(df, axis=0)\n",
    "print(f\"La media del dataset es:\\n{media}\\n\")\n",
    "# Calculando el valor máximo\n",
    "max_val = np.nanmax(df, axis=0)\n",
    "print(f\"El valor máximo de cada variable del dataset es:\\n{max_val}\\n\")\n",
    "# Calculando el valor mínimo\n",
    "min_val = np.nanmin(df, axis=0)\n",
    "print(f\"El valor mínimo de cada variable del dataset es:\\n{min_val}\\n\")\n",
    "# Calculando el rango\n",
    "rango_val = max_val - min_val\n",
    "print(f\"El rango de cada variable del dataset es:\\n{rango_val}\\n\")\n",
    "# Calculando la desviación estándar\n",
    "desv_val = np.nanstd(df, axis=0)\n",
    "print(f\"La desviación estándar de cada variable del dataset es:\\n{desv_val}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma para cada variable del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se itera sobre cada variable del dataset\n",
    "for i in range(df.shape[1]):\n",
    "    sns.distplot(df[:,i])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eab13fdaf92fe66898558a4fc352f13342b3268e938f56df5b50e029ef1bf702"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
